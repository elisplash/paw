---
title: "Installation"
icon: "download"
description: "Install Visual Studio Build Tools with the \"Desktop development with C++\" workload and the Windows 10/11 SDK."
---

# Installation

## Prerequisites

| Requirement | Version | Install |
|-------------|---------|---------|
| **Node.js** | 18+ | [nodejs.org](https://nodejs.org/) |
| **Rust** | Latest stable | [rustup.rs](https://rustup.rs/) |
| **Platform deps** | — | See [Tauri prerequisites](https://v2.tauri.app/start/prerequisites/) |

### Linux (Debian/Ubuntu)

```bash
sudo apt update
sudo apt install libwebkit2gtk-4.1-dev build-essential curl wget file \
  libxdo-dev libssl-dev libayatana-appindicator3-dev librsvg2-dev
```

### macOS

```bash
xcode-select --install
```

### Windows

Install [Visual Studio Build Tools](https://visualstudio.microsoft.com/visual-cpp-build-tools/) with the "Desktop development with C++" workload and the Windows 10/11 SDK.

## Clone and build

```bash
# Clone the repository
git clone https://github.com/elisplash/paw.git
cd paw

# Install frontend dependencies
npm install

# Run in development mode (hot-reload)
npm run tauri dev
```

The first build will take a few minutes while Rust compiles all dependencies. Subsequent builds are incremental and much faster.

## Production build

```bash
npm run tauri build
```

The built app will be in `src-tauri/target/release/bundle/` — platform-specific installer (.dmg, .deb, .msi, etc.).

## Verify

After launching, Pawz opens to the Today dashboard. Go to **Settings** to configure your first AI provider, then you're ready to create agents and start chatting.

## Optional: Ollama (local AI)

For fully local AI with no API keys:

```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Pull a model
ollama pull llama3.1

# Pull the embedding model (for memory)
ollama pull nomic-embed-text
```

Pawz auto-detects Ollama on `localhost:11434` and will auto-pull the embedding model if needed.
