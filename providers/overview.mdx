---
title: "Providers"
description: "10 AI providers and any OpenAI-compatible API — local or cloud, cheap or powerful."
sidebarTitle: "Overview"
---

# Providers

Providers are the AI backends that power your agents. Pawz supports **10 providers** and any OpenAI-compatible API.

<Note>
Mix local models (Ollama) with cloud providers. Pawz auto-falls back to the next provider if one goes down.
</Note>

---

## Supported providers

<Columns cols={3}>
  <Card title="Ollama" href="/providers/ollama">
    Local inference — no API key needed
  </Card>
  <Card title="OpenAI" href="/providers/openai">
    GPT-4o, o1, o3, o4-mini
  </Card>
  <Card title="Anthropic" href="/providers/anthropic">
    Claude 4 Opus, Sonnet, Haiku
  </Card>
  <Card title="Google" href="/providers/google">
    Gemini 2.5 Pro, Flash
  </Card>
  <Card title="OpenRouter" href="/providers/openrouter">
    200+ models via unified API
  </Card>
  <Card title="DeepSeek" href="/providers/deepseek">
    DeepSeek V3, R1, Coder
  </Card>
  <Card title="Grok" href="/providers/grok">
    xAI's Grok models
  </Card>
  <Card title="Mistral" href="/providers/mistral">
    Mistral Large, Codestral
  </Card>
  <Card title="Moonshot" href="/providers/moonshot">
    Kimi and Moonshot models
  </Card>
  <Card title="Custom" href="/providers/custom">
    Any OpenAI-compatible API
  </Card>
</Columns>

## Adding a provider

1. Go to **Settings → Models**
2. Click **Add Provider**
3. Select the provider type
4. Enter your API key
5. Optionally set a default model and custom base URL

## Model routing

Pawz can automatically route requests to different models based on the context:

| Setting | Purpose |
|---------|---------|
| **Boss model** | Expensive, powerful — used for orchestrator bosses |
| **Worker model** | Cheap, fast — used for channel responses and workers |
| **Specialty models** | Per-specialty overrides (e.g., `coder` → `gemini-2.5-pro`) |
| **Agent models** | Per-agent overrides (highest priority) |
| **Cheap model** | Simple tasks auto-select this model |
| **Auto-tier** | Automatically pick cheap vs. expensive based on task complexity |

**Resolution priority:** agent_models > specialty_models > role-based (boss/worker) > fallback

## Smart prefix matching

When you type a model name, Pawz auto-routes to the right provider:

| Pattern | Routes to |
|---------|-----------|
| `claude*` / `anthropic*` | Anthropic |
| `gemini*` / `google*` | Google |
| `gpt*` / `o1*` / `o3*` / `o4*` | OpenAI |
| Contains `/` (e.g., `meta-llama/llama-3.1`) | OpenRouter |
| Contains `:` (e.g., `llama3.1:8b`) | Ollama |
| Other | Default provider → first configured |

## Provider fallback

If a provider returns a billing, authentication, or rate limit error, Pawz automatically tries other configured providers before failing. This ensures your agents stay responsive even if one provider has issues.

## Budget enforcement

Set a daily budget in **Settings → Engine**:

| Threshold | Action |
|-----------|--------|
| 50% | Warning notification |
| 75% | Warning notification |
| 90% | Warning notification |
| 100% | Requests blocked |

Set to `0` to disable budget limits.

## Multiple providers

You can configure as many providers as you want. Benefits:

- Use different models for different agents
- Automatic fallback if one provider is down
- Mix local (Ollama) and cloud providers
- Use cheap models for routine tasks, expensive for complex ones
